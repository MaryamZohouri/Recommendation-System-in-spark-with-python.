{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1563fcf4-58ee-48ce-9fd9-2e77f4d343cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000024C9FDE4810>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/pyspark/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000024C9FE07D10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/pyspark/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000024C9FDE3AD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/pyspark/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000024C9FDBE010>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/pyspark/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000024C9FDF2E50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/pyspark/\n",
      "ERROR: Could not find a version that satisfies the requirement pyspark (from versions: none)\n",
      "ERROR: No matching distribution found for pyspark\n",
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000226347B39D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/mllib/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000022635180C90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/mllib/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002263513CE10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/mllib/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002263513C110>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/mllib/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000022635150FD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/mllib/\n",
      "ERROR: Could not find a version that satisfies the requirement mllib (from versions: none)\n",
      "ERROR: No matching distribution found for mllib\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall pyspark\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall mllib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecommendation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ALS, MatrixFactorizationModel, Rating\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# load in the data\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "# notes:\n",
    "# you may have trouble with full dataset on just your local machine\n",
    "# if you want to know what's in an RDD, use .take(n), ex:\n",
    "# tmp = p.take(5)\n",
    "# print(tmp)\n",
    "# How MF in Spark API works?\n",
    "\n",
    "%pip install pyspark\n",
    "%pip install mllib\n",
    "# mllib is sort of spark's version of sklearn\n",
    "# MF in spark \n",
    "# ALS: \"Alternative Least Square\" \n",
    "# spark.ml uses ASL to learn latent factors which is a small set of data\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "import os\n",
    "\n",
    "# load in the data\n",
    "data = sc.textFile(\"small_rating.csv\")\n",
    "\n",
    "# filter out header\n",
    "header = data.first() #extract header\n",
    "data = data.filter(lambda row: row != header)\n",
    "\n",
    "# convert into a sequence of Rating objects\n",
    "ratings = data.map(\n",
    "  lambda l: l.split(',')\n",
    ").map(\n",
    "  lambda l: Rating(int(l[0]), int(l[1]), float(l[2]))\n",
    ")\n",
    "\n",
    "# split into train and test\n",
    "train, test = ratings.randomSplit([0.8, 0.2])\n",
    "\n",
    "# train the model\n",
    "K = 10\n",
    "epochs = 10\n",
    "model = ALS.train(train, K, epochs)\n",
    "\n",
    "# evaluate the model\n",
    "\n",
    "# train\n",
    "x = train.map(lambda p: (p[0], p[1]))\n",
    "p = model.predictAll(x).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "ratesAndPreds = train.map(lambda r: ((r[0], r[1]), r[2])).join(p)\n",
    "# joins on first item: (user_id, movie_id)\n",
    "# each row of result is: ((user_id, movie_id), (rating, prediction))\n",
    "mse = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "print(\"train mse: %s\" % mse)\n",
    "\n",
    "\n",
    "# test\n",
    "x = test.map(lambda p: (p[0], p[1]))\n",
    "p = model.predictAll(x).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "ratesAndPreds = test.map(lambda r: ((r[0], r[1]), r[2])).join(p)\n",
    "mse = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "print(\"test mse: %s\" % mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
